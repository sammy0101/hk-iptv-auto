import requests
import re
import datetime
from opencc import OpenCC

# åˆå§‹åŒ–ç¹ç°¡è½‰æ›å™¨
cc = OpenCC('s2t')

# --- è¨­å®šå€ (å·²æ›´æ–°ä½ æä¾›çš„ä¾†æºèˆ‡éæ¿¾è¨­å®š) ---

# 1. ä¾†æºåˆ—è¡¨
SOURCE_URLS = [
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/1300%E4%B8%AA%E7%9B%B4%E6%92%AD%E6%BA%90%E5%85%A8%E9%83%A8%E6%9C%89%E6%95%88%E3%80%90%E5%85%A8%E9%83%A84k%E8%80%81%E7%94%B5%E8%84%91%E5%88%AB%E7%94%A8%E3%80%91.m3u8",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/5000%E4%B8%AA%E7%9B%B4%E6%92%AD%E6%BA%90%E5%85%A8%E9%83%A8%E6%9C%89%E6%95%88.m3u",
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u-m3u8/refs/heads/master/m3u/%E6%88%91%E7%9A%84%E6%92%AD%E6%94%BE%E6%BA%90.m3u8",
    "https://raw.githubusercontent.com/suxuang/myIPTV/refs/heads/main/ipv4.m3u",
    "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv6.m3u",
    "https://raw.githubusercontent.com/YueChan/Live/main/IPTV.m3u",
    "https://raw.githubusercontent.com/Kimentanm/aptv/master/m3u/iptv.m3u",
    "https://raw.githubusercontent.com/yuanzl77/IPTV/main/live.m3u",
    "https://iptv-org.github.io/iptv/countries/hk.m3u",
    "https://raw.githubusercontent.com/joevess/IPTV/main/home.m3u8",
    "https://raw.githubusercontent.com/YanG-1989/m3u/main/Gather.m3u"
]

# 2. é—œéµå­—éæ¿¾ (å·²ç§»é™¤é³³å‡°)
KEYWORDS = [
    "ViuTV", "HOY", "RTHK", "Jade", "Pearl", "J2", "J5", "Now", 
    "æ— çº¿", "ç„¡ç·š", "æœ‰çº¿", "æœ‰ç·š", "ç¿¡ç¿ ", "æ˜ç ", "æ¸¯å°", 
]

# 3. å¿…å‚™çš„å®˜æ–¹/ç©©å®šæº
STATIC_CHANNELS = [
    {"name": "RTHK 31", "url": "https://rthklive1-lh.akamaihd.net/i/rthk31_1@167495/index_2052_av-b.m3u8"},
    {"name": "RTHK 32", "url": "https://rthklive2-lh.akamaihd.net/i/rthk32_1@168450/index_2052_av-b.m3u8"}
]

# --- é‚è¼¯å€ ---

def check_url(url):
    """æª¢æ¸¬éˆæ¥æ˜¯å¦æœ‰æ•ˆ (è¶…æ™‚ 2 ç§’)"""
    try:
        response = requests.get(url, timeout=2, stream=True)
        return response.status_code == 200
    except:
        return False

def fetch_and_parse():
    found_channels = []
    
    # flush=True ç¢ºä¿åœ¨ GitHub Action ä¸­èƒ½å³æ™‚çœ‹åˆ°è¼¸å‡º
    print("ğŸš€ ä»»å‹™é–‹å§‹ï¼æ­£åœ¨æŠ“å–ç¶²è·¯æº...", flush=True)
    
    for index, source in enumerate(SOURCE_URLS):
        print(f"  [{index+1}/{len(SOURCE_URLS)}] æ­£åœ¨è®€å–: {source}", flush=True)
        try:
            # è¨­å®š 15 ç§’è¶…æ™‚ï¼Œé¿å…å¤§æ–‡ä»¶å¡ä½
            r = requests.get(source, timeout=15)
            r.encoding = 'utf-8' # å¼·åˆ¶ç·¨ç¢¼ï¼Œé˜²æ­¢äº‚ç¢¼
            
            if r.status_code != 200:
                print(f"    âš ï¸ ç„¡æ³•è®€å– (Status: {r.status_code})", flush=True)
                continue
            
            lines = r.text.split('\n')
            current_name = ""
            count_added = 0
            
            for line in lines:
                line = line.strip()
                if not line: continue
                
                if line.startswith("#EXTINF"):
                    # æå–é »é“åç¨±
                    match = re.search(r',(.+)$', line)
                    if match:
                        raw_name = match.group(1).strip()
                        
                        # 1. è½‰ç¹é«”
                        converted_name = cc.convert(raw_name)
                        
                        # 2. ä¿®æ­£ã€Œè‡ºã€ç‚ºã€Œå°ã€
                        current_name = converted_name.replace('è‡º', 'å°')
                        
                elif line.startswith("http") and current_name:
                    # æª¢æŸ¥é—œéµå­— (çµ±ä¸€è½‰å°å¯«æ¯”å°)
                    if any(cc.convert(k).replace('è‡º', 'å°').lower() in current_name.lower() for k in KEYWORDS):
                        # å»é‡
                        if not any(c['url'] == line for c in found_channels):
                            found_channels.append({"name": current_name, "url": line})
                            count_added += 1
                    current_name = "" # é‡ç½®
            
            print(f"    âœ… æŠ“å–æˆåŠŸï¼Œæ–°å¢ {count_added} å€‹é »é“", flush=True)
            
        except Exception as e:
            print(f"    âŒ æŠ“å–éŒ¯èª¤: {e}", flush=True)

    return found_channels

def generate_m3u(channels):
    total = len(channels)
    print(f"\nğŸ” å…±æ‰¾åˆ° {total} å€‹æ½›åœ¨é »é“ï¼Œé–‹å§‹æª¢æ¸¬æœ‰æ•ˆæ€§...", flush=True)
    
    final_list = []
    
    # 1. åŠ å…¥éœæ…‹æº
    for static in STATIC_CHANNELS:
        final_list.append(static)
        
    # 2. æª¢æ¸¬ç¶²è·¯æº
    for i, ch in enumerate(channels):
        # é¡¯ç¤ºé€²åº¦ [1/100]
        print(f"[{i+1}/{total}] æª¢æ¸¬: {ch['name']} ...", end=" ", flush=True)
        
        if check_url(ch['url']):
            final_list.append(ch)
            print("ğŸŸ¢ æœ‰æ•ˆ", flush=True)
        else:
            print("ğŸ”´ å¤±æ•ˆ", flush=True)

    # 3. å¯«å…¥æ–‡ä»¶
    content = '#EXTM3U x-tvg-url="https://epg.112114.xyz/pp.xml"\n'
    content += f'# Update: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n'
    
    for item in final_list:
        final_name = item["name"].replace('è‡º', 'å°')
        content += f'#EXTINF:-1 group-title="Hong Kong" logo="https://epg.112114.xyz/logo/{final_name}.png",{final_name}\n'
        content += f'{item["url"]}\n'

    with open("hk_live.m3u", "w", encoding="utf-8") as f:
        f.write(content)

    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±æ”¶éŒ„ {len(final_list)} å€‹æœ‰æ•ˆé »é“ã€‚", flush=True)

if __name__ == "__main__":
    candidates = fetch_and_parse()
    generate_m3u(candidates)
